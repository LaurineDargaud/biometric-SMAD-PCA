{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a01909",
   "metadata": {},
   "source": [
    "# Notebook II - Conduct an experiment with PCA-based Proposed Method\n",
    "Laurine Dargaud, June 2022 (Biometric Systems, DTU course)\n",
    "\n",
    "**Topic: Face Morphing Attack Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c26886",
   "metadata": {},
   "source": [
    "**Parameters to fill in, for training and test dataset:**\n",
    "- DATABASE: `FERETsub` or `FRGCsub`\n",
    "- MORPHING ALGO: `facefusion` or `ubo` or `facemorpher` or `opencv`\n",
    "- size of images, in pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b378c",
   "metadata": {},
   "source": [
    "**Pre-requisites:**\n",
    "- create an empty Experiment repository in `data/S-MAD-Experiments/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6473c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width x Height = 500 x 500\n"
     ]
    }
   ],
   "source": [
    "# name of experiment repository\n",
    "_EXPERIMENT_NUMBER_ = '39bis'\n",
    "\n",
    "# training set parameters\n",
    "_DATABASE_TRAIN_ = 'FERETsub'\n",
    "_MORPHING_ALGO_TRAIN_ = 'ubo'\n",
    "\n",
    "# test set parameters\n",
    "_DATABASE_TEST_ = 'FRGCsub'\n",
    "_MORPHING_ALGO_TEST_ = 'ubo'\n",
    "\n",
    "# size of images\n",
    "_IMAGE_WIDTH_ = _IMAGE_HEIGHT_ = 500\n",
    "print('Width x Height =', _IMAGE_WIDTH_, 'x', _IMAGE_HEIGHT_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9327d",
   "metadata": {},
   "source": [
    "## Global Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be04bde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/S-MAD-Experiments/39bis/\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "_EXPERIMENT_PATH_ = f'data/S-MAD-Experiments/{_EXPERIMENT_NUMBER_}/'\n",
    "print(_EXPERIMENT_PATH_)\n",
    "\n",
    "all_files_in_exp_repo = [f for f in listdir(_EXPERIMENT_PATH_) if isfile(join(_EXPERIMENT_PATH_, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b852c",
   "metadata": {},
   "source": [
    "## Phase 1 - generate TRAINING SET and TEST SET file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ac62c",
   "metadata": {},
   "source": [
    "### Import & Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198ff09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Xy(aDatabaseName, aMorphingAlgo, aTransformation = None, ratioBF = None, ratioM = None, merge_bf_m=True):\n",
    "    # generate paths\n",
    "    if aTransformation==None:\n",
    "        bf_target_path = f'data/{aDatabaseName}-Processed/bona-fide/'\n",
    "        morph_target_path = f'data/{aDatabaseName}-Processed/morphed-{aMorphingAlgo}/'\n",
    "    else:\n",
    "        bf_target_path = f'data/{aDatabaseName}-Processed/bona-fide-{aTransformation}/'\n",
    "        morph_target_path = f'data/{aDatabaseName}-Processed/morphed-{aMorphingAlgo}-{aTransformation}/'\n",
    "    print('BF path:', bf_target_path)\n",
    "    print('Morphed path:', morph_target_path)\n",
    "    # load feature pics\n",
    "    bf_features_filenames = [bf_target_path+f for f in listdir(bf_target_path) if isfile(join(bf_target_path, f))]\n",
    "    m_features_filenames = [morph_target_path+f for f in listdir(morph_target_path) if isfile(join(morph_target_path, f))]\n",
    "    # apply ratio if needed\n",
    "    if ratioBF != None:\n",
    "        if ratioBF < 1:\n",
    "            bf_features_filenames = random.sample(bf_features_filenames,int(ratioBF*len(bf_features_filenames)))\n",
    "        else:\n",
    "            bf_features_filenames = random.sample(bf_features_filenames,int(ratioBF))\n",
    "    if ratioM != None:\n",
    "        if ratioM < 1:\n",
    "            m_features_filenames = random.sample(m_features_filenames,int(ratioM*len(m_features_filenames)))\n",
    "        else:\n",
    "            m_features_filenames = random.sample(m_features_filenames,int(ratioM))\n",
    "    # print sizes\n",
    "    print('Number of Bona Fide pictures: ', len(bf_features_filenames))\n",
    "    print('Number of Morphed pictures: ', len(m_features_filenames))\n",
    "    if merge_bf_m:\n",
    "        # create merged X and y variables\n",
    "        X = bf_features_filenames+m_features_filenames\n",
    "        y = len(bf_features_filenames)*[0]+len(m_features_filenames)*[1]\n",
    "        return X, y\n",
    "    return bf_features_filenames, m_features_filenames, len(bf_features_filenames)*[0], len(m_features_filenames)*[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77b302",
   "metadata": {},
   "source": [
    "### MAIN to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4090073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== TRAINING SET ==\n",
      "BF path: data/FERETsub-Processed/bona-fide/\n",
      "Morphed path: data/FERETsub-Processed/morphed-ubo/\n",
      "Number of Bona Fide pictures:  622\n",
      "Number of Morphed pictures:  529\n",
      "\n",
      "-- Proportion of positive labels: 0.4596003475238923\n",
      "\n",
      "== TEST SET ==\n",
      "BF path: data/FRGCsub-Processed/bona-fide/\n",
      "Morphed path: data/FRGCsub-Processed/morphed-ubo/\n",
      "Number of Bona Fide pictures:  1274\n",
      "Number of Morphed pictures:  964\n",
      "\n",
      "-- Proportion of positive labels: 0.4307417336907953\n"
     ]
    }
   ],
   "source": [
    "if (_MORPHING_ALGO_TRAIN_ == _MORPHING_ALGO_TEST_) and (_DATABASE_TRAIN_ == _DATABASE_TEST_):\n",
    "    # CASE: training and test on the same dataset -> 70/30 split\n",
    "    _MORPHING_ALGO_ = _MORPHING_ALGO_TRAIN_\n",
    "    _DATABASE_ = _DATABASE_TRAIN_\n",
    "    # generate all files\n",
    "    print('== DATASET ==')\n",
    "    X, y = generate_Xy(_DATABASE_, _MORPHING_ALGO_)\n",
    "    # split train and test sets\n",
    "    X_filenames_train, X_filenames_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "    print('\\n-- Proportion of positive labels in training set:', np.mean(y_train))\n",
    "    print('-- Proportion of positive labels in test set:', np.mean(y_test))\n",
    "    \n",
    "elif (_DATABASE_TRAIN_ == _DATABASE_TEST_) and (_MORPHING_ALGO_TRAIN_ != _MORPHING_ALGO_TEST_):\n",
    "    # CASE: Same database but different morphing algorithms\n",
    "    _MORPHING_ALGO_ = _MORPHING_ALGO_TRAIN_+'>>'+_MORPHING_ALGO_TEST_\n",
    "    _DATABASE_ = _DATABASE_TRAIN_\n",
    "    # in this case: X_filenames_train_bf == X_filenames_test_bf & y_train_bf == y_test_bf\n",
    "    X_filenames_bf, X_filenames_train_m, y_bf, y_train_m = generate_Xy(_DATABASE_TRAIN_, _MORPHING_ALGO_TRAIN_, merge_bf_m=False)\n",
    "    print('\\n')\n",
    "    _, X_filenames_test_m, _, y_test_m = generate_Xy(_DATABASE_TEST_, _MORPHING_ALGO_TEST_, merge_bf_m=False)\n",
    "    # SPLIT: 70/30 split for BF, balanced datasets\n",
    "    # 70/30 for BF\n",
    "    X_filenames_train_bf, X_filenames_test_bf, y_train_bf, y_test_bf = train_test_split(X_filenames_bf, y_bf, test_size=0.3, random_state=42, shuffle=True)\n",
    "    # keep 70% of Train morphs (balanced)\n",
    "    X_filenames_train_m, _, y_train_m, _ = train_test_split(X_filenames_train_m, y_train_m, test_size=0.3, random_state=42, shuffle=True)\n",
    "    # keep 30% of Test morphs (balanced)\n",
    "    _, X_filenames_test_m, _, y_test_m = train_test_split(X_filenames_test_m, y_test_m, test_size=0.3, random_state=42, shuffle=True)\n",
    "    # merge to obtain 2 X_filenames and 2 y lists\n",
    "    X_filenames_train = list(X_filenames_train_bf) + list(X_filenames_train_m)\n",
    "    X_filenames_test = list(X_filenames_test_bf) + list(X_filenames_test_m)\n",
    "    y_train = list(y_train_bf) + list(y_train_m)\n",
    "    y_test = list(y_test_bf) + list(y_test_m)\n",
    "    print('\\n== TRAINING SET ==')\n",
    "    print(f'{len(X_filenames_train_bf)} Bona Fide images + {len(X_filenames_train_m)} {_MORPHING_ALGO_TRAIN_} morphed images')\n",
    "    print('-- Proportion of positive labels:', np.mean(y_train))\n",
    "    print('\\n== TEST SET ==')\n",
    "    print(f'{len(X_filenames_test_bf)} remaining Bona Fide images + {len(X_filenames_test_m)} {_MORPHING_ALGO_TEST_} morphed images')\n",
    "    print('-- Proportion of positive labels:', np.mean(y_test))\n",
    "    \n",
    "else:\n",
    "    # CASE: different databases\n",
    "    _MORPHING_ALGO_ = _MORPHING_ALGO_TRAIN_+'>>'+_MORPHING_ALGO_TEST_\n",
    "    _DATABASE_ = _DATABASE_TRAIN_+'>>'+_DATABASE_TEST_\n",
    "    # generate X_filenames_train and y_train\n",
    "    print('== TRAINING SET ==')\n",
    "    X_filenames_train, y_train = generate_Xy(_DATABASE_TRAIN_, _MORPHING_ALGO_TRAIN_)\n",
    "    print('\\n-- Proportion of positive labels:', np.mean(y_train))\n",
    "\n",
    "    # generate X_filenames_test and y_test\n",
    "    print('\\n== TEST SET ==')\n",
    "    X_filenames_test, y_test = generate_Xy(_DATABASE_TEST_, _MORPHING_ALGO_TEST_)\n",
    "    print('\\n-- Proportion of positive labels:', np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01484a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_set_size': 1151, 'test_set_size': 2238, 'nb_morphed_in_training': 529, 'nb_morphed_in_test': 964, 'height': 500, 'width': 500, 'morphing_algo': 'ubo>>ubo', 'dataset': 'FERETsub>>FRGCsub'}\n"
     ]
    }
   ],
   "source": [
    "# save them as txt files in experiment repository\n",
    "\n",
    "# save filenames\n",
    "txt_train = ';'.join(X_filenames_train)\n",
    "txt_test = ';'.join(X_filenames_test)\n",
    "\n",
    "with open(_EXPERIMENT_PATH_+'X_filenames_train.txt', 'w') as f:\n",
    "    f.write(txt_train)\n",
    "with open(_EXPERIMENT_PATH_+'X_filenames_test.txt', 'w') as f:\n",
    "    f.write(txt_test)\n",
    "    \n",
    "# save targets\n",
    "np.savetxt(_EXPERIMENT_PATH_+'y_train.txt', y_train, delimiter=\";\")\n",
    "np.savetxt(_EXPERIMENT_PATH_+'y_test.txt', y_test, delimiter=\";\")\n",
    "\n",
    "# save infos\n",
    "experiment_infos = {\n",
    "    'training_set_size':len(y_train),\n",
    "    'test_set_size':len(y_test),\n",
    "    'nb_morphed_in_training':np.sum(y_train),\n",
    "    'nb_morphed_in_test':np.sum(y_test),\n",
    "    'height':_IMAGE_HEIGHT_,\n",
    "    'width':_IMAGE_WIDTH_,\n",
    "    'morphing_algo':_MORPHING_ALGO_,\n",
    "    'dataset':_DATABASE_\n",
    "}\n",
    "print(str(experiment_infos))\n",
    "\n",
    "with open(_EXPERIMENT_PATH_+'infos.txt', 'w') as f:\n",
    "    f.write(str(experiment_infos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887094c",
   "metadata": {},
   "source": [
    "## Phase 2 - run PCA for each color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c95506",
   "metadata": {},
   "source": [
    "### Imports & Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112dd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b0fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(anImage):\n",
    "    return cv2.cvtColor(anImage, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def get_data_matrix(aXfilenames, H = _IMAGE_HEIGHT_, W = _IMAGE_WIDTH_):\n",
    "    # get the number of pictures in the training set\n",
    "    N = len(aXfilenames)\n",
    "\n",
    "    # get height and width of image\n",
    "    M = H*W\n",
    "\n",
    "    # create N*M data matrix of zeros\n",
    "    data = np.zeros((M,N))\n",
    "\n",
    "    # fill the empty matrix so that each column is one face image\n",
    "    for k in range (N):\n",
    "        # read image\n",
    "        img = cv2.imread(aXfilenames[k])\n",
    "        # resize\n",
    "        if img.shape[:2] != (W,H):\n",
    "            img = cv2.resize(img, (W,H))\n",
    "        # process image\n",
    "        img = process_image(img)\n",
    "        # reshape\n",
    "        tt = np.reshape(img, M)\n",
    "        # fill data matrix\n",
    "        data[:,k] = tt\n",
    "\n",
    "    X = data.T\n",
    "    return X\n",
    "\n",
    "def change_color_channel_in_path(aPath, aColorChannel):\n",
    "    result = aPath.split('/')\n",
    "    result[-2] = result[-2]+f'-lpb-{aColorChannel}comp-cropped'\n",
    "    return '/'.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9cb1d",
   "metadata": {},
   "source": [
    "### MAIN to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8845f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NB_COMPONENTS_ = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d6094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt files from experiment\n",
    "with open(_EXPERIMENT_PATH_+'X_filenames_train.txt') as f:\n",
    "    X_filenames_train = f.readlines()[0]\n",
    "    X_filenames_train = X_filenames_train.split(';')\n",
    "\n",
    "with open(_EXPERIMENT_PATH_+'X_filenames_test.txt') as f:\n",
    "    X_filenames_test = f.readlines()[0]\n",
    "    X_filenames_test = X_filenames_test.split(';')\n",
    "    \n",
    "y_train = np.loadtxt(_EXPERIMENT_PATH_+'y_train.txt', delimiter=';')\n",
    "y_test = np.loadtxt(_EXPERIMENT_PATH_+'y_test.txt', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8108b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA for R...\n",
      "  Projecting X_train into PC space...\n",
      "  Projecting X_test into PC space...\n",
      "  Saving results...\n",
      "\n",
      "Running PCA for G...\n",
      "  Projecting X_train into PC space...\n",
      "  Projecting X_test into PC space...\n",
      "  Saving results...\n",
      "\n",
      "Running PCA for B...\n",
      "  Projecting X_train into PC space...\n",
      "  Projecting X_test into PC space...\n",
      "  Saving results...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for aColorChannel in ['R', 'G', 'B']:\n",
    "    if f'X_train_transformed_{aColorChannel}.txt' not in all_files_in_exp_repo:\n",
    "        # generate path of color channel features repo\n",
    "        X_filenames_train_color = list(map(lambda p: change_color_channel_in_path(p, aColorChannel), X_filenames_train))\n",
    "        X_filenames_test_color = list(map(lambda p: change_color_channel_in_path(p, aColorChannel), X_filenames_test))\n",
    "        # run PCA\n",
    "        print(f'Running PCA for {aColorChannel}...')\n",
    "        X_train = get_data_matrix(X_filenames_train_color)\n",
    "        pca = PCA(_NB_COMPONENTS_).fit(X_train)\n",
    "        # save pca\n",
    "        dump(pca, _EXPERIMENT_PATH_+f'pca{aColorChannel}.joblib') \n",
    "        # project training set into PC space\n",
    "        print('  Projecting X_train into PC space...')\n",
    "        X_train_transformed = pca.transform(X_train)\n",
    "        # project test set into PC space\n",
    "        print('  Projecting X_test into PC space...')\n",
    "        X_test = get_data_matrix(X_filenames_test_color)\n",
    "        X_test_transformed = pca.transform(X_test)\n",
    "        # save PC 2D coordinates of training dataset\n",
    "        print('  Saving results...\\n')\n",
    "        np.savetxt(_EXPERIMENT_PATH_+f'X_train_transformed_{aColorChannel}.txt', X_train_transformed, delimiter=\";\")\n",
    "        # save PC 2D coordinates of test dataset\n",
    "        np.savetxt(_EXPERIMENT_PATH_+f'X_test_transformed_{aColorChannel}.txt', X_test_transformed, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1682c",
   "metadata": {},
   "source": [
    "## Phase 3 - run Bayesian Classification for each color channel + run final classification RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e68c4a1",
   "metadata": {},
   "source": [
    "### Imports & Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2df779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "\n",
    "from exercise5 import compute_err\n",
    "from exercise5 import generate_samples\n",
    "from exercise5 import GaussianProcessModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8747332",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresold = 0.5\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "sigmoid = lambda x: 1./(1+np.exp(-x))\n",
    "y = lambda x:  5*np.sin(0.75*x)\n",
    "\n",
    "def log_lik_bernoulli(y, t): \n",
    "    \"\"\" implement log p(t=1|y) using the sigmoid inverse link function \"\"\"\n",
    "    p = sigmoid(y)\n",
    "    return t.ravel()*np.log(p) + (1-t.ravel())*np.log(1-p)\n",
    "\n",
    "def compute_predictive_prob_MC(mu_y, Sigma_y, sample_size=2000):\n",
    "    \"\"\"\n",
    "        The function computes p(t^* = 1|t, x^*) using Monte Carlo sampling  as in eq. (2).\n",
    "        The function also returns the samples generated in the process for plotting purposes\n",
    "\n",
    "        arguments:\n",
    "        mu_y             -- N x 1 vector\n",
    "        Sigma_y          -- N x N matrix\n",
    "        sample_size      -- positive integer\n",
    "\n",
    "        returns:\n",
    "        p                -- N   vector\n",
    "        y_samples        -- sample_size x N matrix\n",
    "        sigma_samples    -- sample_size x N matrix\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # generate samples from y ~ N(mu, Sigma)\n",
    "    y_samples = generate_samples(mu_y, Sigma_y, sample_size).T \n",
    "\n",
    "    # apply inverse link function (elementwise)\n",
    "    sigma_samples = sigmoid(y_samples)\n",
    "\n",
    "    # return MC estimate, samples of y and sigma(y)\n",
    "    return np.mean(sigma_samples, axis=0), y_samples, sigma_samples\n",
    "\n",
    "def predictive(Xp, aGP):\n",
    "    mu_y, var_y = aGP.compute_posterior_y(Xp, pointwise=True)\n",
    "    p, _, _ = compute_predictive_prob_MC(mu_y, np.diag(var_y))\n",
    "    return p\n",
    "\n",
    "def run_classification(related_channel_short):\n",
    "    print(f'Classification for {related_channel_short} color channel:')\n",
    "    # load files\n",
    "    Xtrain = np.loadtxt(_EXPERIMENT_PATH_+f'X_train_transformed_{related_channel_short}.txt', delimiter=';')\n",
    "    Xtest = np.loadtxt(_EXPERIMENT_PATH_+f'X_test_transformed_{related_channel_short}.txt', delimiter=';')\n",
    "    ttrain = np.loadtxt(_EXPERIMENT_PATH_+'y_train.txt', delimiter=';')\n",
    "    ttest = np.loadtxt(_EXPERIMENT_PATH_+'y_test.txt', delimiter=';')\n",
    "\n",
    "    # make sure dimensions are [N x 1]\n",
    "    ttrain = ttrain[:, None]\n",
    "    ttest = ttest[:, None]\n",
    "\n",
    "    # scale to proper dimensions!!\n",
    "    if related_channel_short != 'RGB':\n",
    "        scale = 0.0001\n",
    "        Xtrain, Xtest = scale*Xtrain, scale*Xtest\n",
    "\n",
    "    X = np.row_stack((Xtrain, Xtest))\n",
    "    t = np.row_stack((ttrain, ttest))\n",
    "\n",
    "    # define prior\n",
    "    kappa = 1.\n",
    "    scale = 1.\n",
    "    theta = [kappa, scale]\n",
    "\n",
    "    # fit classifier and prediction\n",
    "    if related_channel_short == 'RGB':\n",
    "        print('     Running Random Forest...')\n",
    "        best_classifier = 'Random Forest'\n",
    "        clf = RandomForestClassifier(max_depth=2, random_state=42)\n",
    "        clf.fit(Xtrain, ttrain.ravel())\n",
    "        print('     Predicting...')\n",
    "        p_train = clf.predict_proba(Xtrain).T[1]\n",
    "        p_test = clf.predict_proba(Xtest).T[1]\n",
    "    else:\n",
    "        print('     Running Gaussian Process model...')\n",
    "        best_classifier = 'Gaussian Process'\n",
    "        gp = GaussianProcessModel(Xtrain, ttrain, theta, log_lik_bernoulli)\n",
    "        print('     Predicting...')\n",
    "        p_train = predictive(Xtrain, gp)\n",
    "        p_test = predictive(Xtest, gp)\n",
    "\n",
    "    # make predictions\n",
    "    ttrain_hat = 1.0*(p_train > thresold)\n",
    "    ttest_hat = 1.0*(p_test > thresold)\n",
    "\n",
    "    # print results: mean and standard error of the mean\n",
    "    print('     - Training error:\\t%3.2f (%3.2f)' % compute_err(ttrain_hat.ravel(), ttrain.ravel()))\n",
    "    print('     - Test error:\\t%3.2f (%3.2f)' % compute_err(ttest_hat.ravel(), ttest.ravel()))\n",
    "\n",
    "    # compute performance scores\n",
    "    NFCM = np.sum(ttest.ravel() > ttest_hat.ravel())\n",
    "    MFCN = np.sum(ttest.ravel() < ttest_hat.ravel())\n",
    "    NFCM = NFCM/(len(ttest.ravel())-np.sum(ttest.ravel()))\n",
    "    MFCN = MFCN/(np.sum(ttest.ravel()))\n",
    "    ACER = (NFCM+MFCN)/2\n",
    "\n",
    "    print(f'         NFCM = {round(NFCM*100,3)}%')\n",
    "    print(f'         MFCN = {round(MFCN*100,3)}%')\n",
    "    print(f'         >>>> ACER = {round(ACER*100,3)}%')\n",
    "\n",
    "    # export results\n",
    "    performance_results = {\n",
    "        'NFCM':NFCM,\n",
    "        'MFCN':MFCN,\n",
    "        'ACER':ACER,\n",
    "        'classifier':best_classifier,\n",
    "        'threshold':thresold\n",
    "    }\n",
    "\n",
    "    with open(_EXPERIMENT_PATH_+f'results_{related_channel_short}.txt', 'w') as f:\n",
    "        f.write(str(performance_results))\n",
    "\n",
    "    # export probas\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'y_train_probas_{related_channel_short}.txt', p_train, delimiter=\";\")\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'y_test_probas_{related_channel_short}.txt', p_test, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95d4be",
   "metadata": {},
   "source": [
    "### MAIN to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a600d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for R color channel:\n",
      "     Running Gaussian Process model...\n",
      "     Predicting...\n",
      "     - Training error:\t0.14 (0.01)\n",
      "     - Test error:\t0.14 (0.01)\n",
      "         NFCM = 6.515%\n",
      "         MFCN = 24.793%\n",
      "         >>>> ACER = 15.654%\n",
      "Classification for G color channel:\n",
      "     Running Gaussian Process model...\n",
      "     Predicting...\n",
      "     - Training error:\t0.13 (0.01)\n",
      "     - Test error:\t0.11 (0.01)\n",
      "         NFCM = 16.876%\n",
      "         MFCN = 2.697%\n",
      "         >>>> ACER = 9.787%\n",
      "Classification for B color channel:\n",
      "     Running Gaussian Process model...\n",
      "     Predicting...\n",
      "     - Training error:\t0.11 (0.01)\n",
      "     - Test error:\t0.13 (0.01)\n",
      "         NFCM = 21.9%\n",
      "         MFCN = 0.207%\n",
      "         >>>> ACER = 11.053%\n",
      "Classification for RGB color channel:\n",
      "     Running Random Forest...\n",
      "     Predicting...\n",
      "     - Training error:\t0.11 (0.01)\n",
      "     - Test error:\t0.10 (0.01)\n",
      "         NFCM = 16.641%\n",
      "         MFCN = 1.141%\n",
      "         >>>> ACER = 8.891%\n"
     ]
    }
   ],
   "source": [
    "for related_channel_short in ['R','G','B']:\n",
    "    \n",
    "    if f'y_test_probas_{related_channel_short}.txt' not in all_files_in_exp_repo:\n",
    "        run_classification(related_channel_short)\n",
    "\n",
    "# create data\n",
    "if f'X_train_transformed_RGB.txt' not in all_files_in_exp_repo:\n",
    "    X_train_transformed, X_test_transformed = [], []\n",
    "\n",
    "    for aSymbol in ['R','G','B']:\n",
    "        # get y_train_probas\n",
    "        y_train_probas = np.loadtxt(_EXPERIMENT_PATH_+f'y_train_probas_{aSymbol}.txt', delimiter=';')\n",
    "        # get y_test_probas\n",
    "        y_test_probas = np.loadtxt(_EXPERIMENT_PATH_+f'y_test_probas_{aSymbol}.txt', delimiter=';')\n",
    "        X_train_transformed.append(y_train_probas)\n",
    "        X_test_transformed.append(y_test_probas)\n",
    "\n",
    "    X_train_transformed = np.array(X_train_transformed).T\n",
    "    X_test_transformed = np.array(X_test_transformed).T\n",
    "\n",
    "    # save PC 2D coordinates of training dataset\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'X_train_transformed_RGB.txt', X_train_transformed, delimiter=\";\")\n",
    "\n",
    "    # save PC 2D coordinates of test dataset\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'X_test_transformed_RGB.txt', X_test_transformed, delimiter=\";\")\n",
    "\n",
    "# run final classification\n",
    "run_classification('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e20ab0",
   "metadata": {},
   "source": [
    "## Phase 4 - create mated and nonmated txt files for DET script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159a558",
   "metadata": {},
   "source": [
    "### Imports & Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b98a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701d0e7",
   "metadata": {},
   "source": [
    "### MAIN to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e04a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(_EXPERIMENT_PATH_+'y_test.txt', delimiter=';')\n",
    "\n",
    "y_test_morphedIdx = np.argwhere(y_test == 1).ravel()\n",
    "y_test_bonafideIdx = np.argwhere(y_test == 0).ravel() \n",
    "\n",
    "for aColorChannel in ['R','G','B','RGB']:\n",
    "    y_test_probas = np.loadtxt(_EXPERIMENT_PATH_+f'y_test_probas_{aColorChannel}.txt', delimiter=';')\n",
    "    y_test_mated_probas = y_test_probas[y_test_bonafideIdx]\n",
    "    y_test_nonmated_probas = y_test_probas[y_test_morphedIdx]\n",
    "    # save files\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'mated{aColorChannel}.txt', y_test_mated_probas, delimiter=\"\\t\")\n",
    "    np.savetxt(_EXPERIMENT_PATH_+f'nonmated{aColorChannel}.txt', y_test_nonmated_probas, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a85981",
   "metadata": {},
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe061f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '37bis', '38', '39', '39bis', '40', '40bis', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71']\n"
     ]
    }
   ],
   "source": [
    "def file2dict(aPath):\n",
    "    with open(aPath) as f:\n",
    "        result = f.readlines()[0]\n",
    "        result = ast.literal_eval(result)\n",
    "    return result\n",
    "\n",
    "def dict_report(aDict, title):\n",
    "    result = '>> '+title + '\\n'\n",
    "    for k,v in aDict.items():\n",
    "        result += f'\\t{k}: {v}\\n'\n",
    "    return result+'\\n'\n",
    "\n",
    "import ast\n",
    "\n",
    "_GLOBAL_EXPERIMENT_PATH_ = 'data/S-MAD-Experiments/'\n",
    "\n",
    "experiments_directories = [f for f in listdir(_GLOBAL_EXPERIMENT_PATH_) if isdir(join(_GLOBAL_EXPERIMENT_PATH_, f))]\n",
    "print('Experiments:',experiments_directories)\n",
    "\n",
    "final_report = ''\n",
    "\n",
    "# generate report\n",
    "for anExp in experiments_directories:\n",
    "    final_report = f'=== EXPERIMENT {anExp} ===\\n\\n'\n",
    "    path = _GLOBAL_EXPERIMENT_PATH_+str(anExp)+'/'\n",
    "    # all files in the experiment repo\n",
    "    allFiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    # read notes\n",
    "    if 'notes.txt' in listdir(path):\n",
    "        with open(path+'notes.txt') as f:\n",
    "            notes = f.readlines()\n",
    "            final_report += '* NOTES *\\n'+''.join(notes)+'\\n\\n'\n",
    "    # read infos\n",
    "    expInfos = file2dict(path+'infos.txt')\n",
    "    final_report += dict_report(expInfos, 'INFOS')\n",
    "    all_results_filenames = {\n",
    "        'B':'Blue Component','G':'Green Component', 'R':'Red Component','Gray':'Grayscale',\n",
    "        'H':'Hue Component','S':'Saturation Component', 'V':'Value Component'\n",
    "    }\n",
    "    # read results\n",
    "    for k,v in all_results_filenames.items():\n",
    "        if (f'results_{k}.txt' in allFiles):\n",
    "            results = file2dict(path+f'results_{k}.txt')\n",
    "            final_report += dict_report(results, f'{v} Results')\n",
    "    # export\n",
    "    with open(_GLOBAL_EXPERIMENT_PATH_+f'reportExp{anExp}.txt', 'w') as f:\n",
    "        f.write(final_report)\n",
    "\n",
    "# merge all reports into one final report\n",
    "final_report = ''\n",
    "experiments_reports_files= [_GLOBAL_EXPERIMENT_PATH_+f for f in listdir(_GLOBAL_EXPERIMENT_PATH_) if (isfile(join(_GLOBAL_EXPERIMENT_PATH_, f)) and 'reportExp' in f)]\n",
    "\n",
    "for aReport in experiments_reports_files:\n",
    "        with open(aReport) as f:\n",
    "            notes = f.readlines()\n",
    "            final_report += ''.join(notes)+'\\n\\n'\n",
    "\n",
    "with open(_GLOBAL_EXPERIMENT_PATH_+f'MERGED-REPORT.txt', 'w') as f:\n",
    "        f.write(final_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ec7ca",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
